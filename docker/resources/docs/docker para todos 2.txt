docker para todos 2

* conectar con un segundo daemon:

docker context ls

(solo aparece el local)

Si queremos ejecutar comandos en otro daemon sin conectar por ssh a ese daemon:

$ DOCKER_HOST="tcp://ip:2375"

En este caso tendremos la API abierta por TCP (menos seguro)

Para conectar teniendolo configurado en local (el daemon externo)

usamos docker context

$ docker context create --docker "host=tcp://ip:2375" pwd
$ docker contetext ls

podemos hacer un switch de context para usar el nuevo daemon:

$ docker context use pwd


podemos configurar conexiones por ssl o hacer un skip de certificados auto-creados

Es posible configurar el archivo de configuración que se ha generado, por si quisieramos modificar directamente algunos parámetros de la conexion del daemon:

$ cd ~/.docker/contexts/meta/{id}
$ vi meta.json

* A partir de la versión 18, podemos conectar con un daemon remoto mediante SSH.

$ docker context create ssh --docker "host=ssh://myremotehost"

Para utilizar "hostaname" en vez de una cadena de conexión propia de ssh (ssh -l usuario host --parametros) deberíamos de crear una configuración ssh en nuestro archivo de configuración ssh local.

Aquí un ejemplo en el que se accede por ssh a "miremotehost" evitando el fingerprint del hostname remoto, y utilizando un certificado .pem en vez de password.

$ cat ~/.ssh/config

Host myremotehost
  StrickHostKeyCheking no
  Hostname 3.210.133.101
  User ubuntu
  IdentityFile ~/.ssh/myremotehost.pem


* Otra característica de la versión 19 es docker app. Es una opción para compartir aplicaciones de forma mas facil, a traves de paquetes tar en git.

Docker app se instala como un plugin en docker 19.83 y en esta versión aún hay que configurar ~/.docker/config.json para que docker trabaje en experimental:

cd; vi .docker/config.json
{
	"experimental": "enabled"
}

$ 

Docker client plugins Manager : lukaszlach/clip

* Mirar también docker buildx


* Mirar también docker cluster

Preguntas frecuentes:

1. Sobre la seguridad en las imágenes Alpile

Es muy segura debida a la cantidad de archivos, binarios, programas, que han sido eliminados. Uno de los lemas es menos paching, mas seguro.

No obstante, es recomendable ir a producción con imágenes basadas en aquellos sistemas operativos qu acostumbremos usar (Debian, Ubuntu, RHEL, CentOS) debido a que Alpine cambia aspectos importantes como el propio gestor de paquetes, ubicación de archivos y binarios, etc... por lo que al final, si no estás acostumbrado a Alpine, tendrás que realizar un gran esfuerzo al principio, e incluso acostumbrarte a este OS, si quieres ir a producción con los menos problemas posibles. EN la mayoría de los casos, este esfuerzo te hará ahorar algunos MB en tu disco, algo que no es especialmente significativo hoy en día.

Un inconveniente de usar Alpine y tal y como se define en (https://kubedex.com/follow-up-scanning-comparison) es el problema que tienen los escaneadores de vulnerabilidades. Alpine, al modificar rutas de archivos o incluso los distributions back-port patches los escaneadores no encuentren vulnerabilidades en sus paquetes.

2. Apache:

Es buena práctica crear un contenedor con Apache + site de forma asislada a ejecutar un contenedor con Apache + multisite. Esto principalmente es por escalabilidad de un site concreto, la actualización del web site (no tener que tirar todos e iniciar todos)... si tuvieramos cientos de sites, igual conviene agruparlos de forma coherente por contenedores, para optimizar recursos en el servidor.

3. Bases de datos en VM's continers o bare


4. Compose vs swarm en un solo servidor: la recomendación es usar siempre swarm en producción aunque solo sea un host debido a que haremos uso de las ventajas de swarm por ejemplo para hacer un rolling upgrade, o actualizaciones, etc... no tendremos downtime, ni tener que re-hacer todo el trabajo. Además siempre estaremos preparados para escalar.


5. Docker environment configuration

	The twelve-Factor APP (12factor.net/config)

	-> Factores a tener en cuenta al desplegar infraestructuras microservicios.

6. ENTRYPOINT vs CMD

El ENTRYPOINT por defecto (si no se ejecuta el comando ENTRYPOINT dentro del Dockerfile, el cual referencia a un ShellScript) es "/bin/sh -c" es decir se prepara para ejecutar un comando a partir de sh, que comando? pues el que hayamos marcado para ejecutar en la entrada CMD del Dockerfile.

Existen varias formas de anular, sobreescribir o utilizar estas dos entradas de Dockerfile

1. No usamos entrypoint pero si un CMD dentro del Dockerfile

* CMD: ["/bin/echo","Hello World!"]

Resultado al inicializar el contenedor:
	El último comando en ejecutarse tras instanciar el contenedor será:

		$ /bin/sh -c "echo Hello World!"

2. Sobreescribimos el CMD:

	$ docker container run --rm image /bin/ls
	bin
	boot
	dev
	etc
	home
	...

3. Utilizar las entradas ENTRYPOINT y CMD en Dockerfile

	FROM ubuntu:16.04
	ENTRYPOINT ["/bin/echo"]
	CMD ["Hello World!"]

El resultado será el mismo que el del punto 1.

4. Sobreescribir el CMD. Este caso es diferente al punto 2 debido a que en el punto 2 no usábamos ningún ENTRYPOINT por lo tanto se ejecutaba el comando 'ls' a través de /bin/sh -c. Ahora el ENTRYPOINT es un /bin/echo y por ello el valor con el que vamos a sustituir al CMD del paso 3, será un argumento para echo.

	$ docker container run --rm image "Esto difiere del punt 2."
	Esto difiere del punt 2.

5. Por último, veremos como sustituir en tiempo de ejecución tanto en ENTRYPOINT como el CMD del Dockerfile. Suponiendo que continuamos con la imagen cosntruida a partir del paso 3. Vamos a modificar el ENTRYPOINT por "/bin/cat" y el CMD por "/etc/release" con lo cual, al instanciar el contenedor, nos imprimirá la versión del OS.

	$ docker container run --rm --entrypoint="/bin/cat" test /etc/lsb-release
	DISTRIB_ID=Ubuntu
	DISTRIB_RELEASE=16.04
	DISTRIB_CODENAME=xenial
	DISTRIB_DESCRIPTION="Ubuntu 16.04.6 LTS"

Ahora que ya hemos visto las sintaxis del comando ENTRYPOINT y CMD dentro de y fuera de un Dockerfile, decir que estábamos utilizando una de las dos formas en las que estos comandos pueden ser instanciados, en este caso usábamos la "exec form" (["valor1","valor2",...]). La otra forma es la utilizada por el comando RUN del Dockerfile y que también es posible para los dos comandos anteriores y es la "shell form" (<instrucción> <comando>). Veamos un ejemplo:

  	FROM ubuntu:16.04
  	RUN apt update && \
  	  apt install wget -y
  	ENV msg "Hello World!"
  	ENTRYPOINT echo "$msg"

 En este ejemplo hemos añadido la definición de una variable y un ENTRYPOINT. Todos los comandos definidos en este Dockerfile están en "Shell form".

 Para terminar, entonces podemos decir que lo definido en el comando ENTRYPOINT se ejecuta siempre antes de lo definido en CMD y que en la mayoría de las veces, se usa CMD para pasar parámetros a un comando que se ejecutará desde dentro de un Shell Script. Este Shell script será ejecutado a su vez por ENTRYPOINT. Un ejemplo es cuando ENTRYPOINT define un shellscript de configuración de un servicio, por ejemplo nginx o mysql y en su último comando, define un comando para inicializar el servicio en si, en CMD podremos entonces ver algunos parámetros que se le pasarán a este servicio.

6. Estudiar el tema de como usar variables de entornos en Docker y sobretodo como administrar secrets, fuera parte de los métodos de swarm y kubernetes. El entrypoint de mysql oficial tiene algo curioso que no term,ino de descifrar.

7. Dividir muchos vhost de apache en muchos contenedores tiene la particularidad de que es muy fácil manejar de forma independiente las applicaciones, rolling update, escalado, etc... pero la deventaja de que estamos gastando muchos mas recursos al tener tantos apache en la misma máquina. Igual pasa con contenedores de servidores de aplicaciones como tomcat, jboss, oas, etc... Lo mejor es valorar todo, y separar aquello que sea mas dinámico para dejar mas "estanco" lo menos cambiante o aquello que es mas fácil de migrar en un futuro aunque sea cambiante (por ejemplo, la versión del servidor de aplicaciones puede incrementar a consecuencia de nuevos parches y soluciones pero la applicación es poco pesada y facil de administrar y migrar, esto seguramente iría mejor en servidores dedicados.)



* mirar let's encrypt, es una página buena para saber que debemos y que no hacer con la generacion de certificados en local.

* mirar stack-proxy-global para temas decertificados en proxy, etc...


* Probar lo del entrypoint: escribir un shell con funciones etc... que haga cosas al iniciar el servicio y por ultimo coja el CMD como parámetro de la inicialización del servicio. Podemos probar esto con cosas faciles como sustituir valor de variable dada por el CMD como argumento etc...

 * otra práctica es iniciar un stack de aplicaciones en orden. Para esto Bret menciona que están disponible los comandos de compose como respawn, depend_on, etc... en 12 factor también podemos encontrar algo. Montar un stack y conseguir que se orquestre bein.


 * EN los dockerfile hay que tener especial cuidado con los apt get update, ya que poner un solo update al inicio pensando de que actualizara la cache de los paquetes no será cerieto, ya que lo actualizara (los repo) la priemra vez que constuyamos la imagen pero si volvemos a modificar el docker file, incluso incluyendo posteriores apt install de paquetes, ese paso no se olverá a ejecutar porque ya está en la cache de la imagen y esa linea del dockerfile no ha cambiado. El update debe incluirse antes de cualquier RUN apt install que haya en el dockerfile. Recordar puntualizar las versiones de los paquetes al instalar para fijar las verdiones a usar.

 cuando descargamos archivos de internet, solemos usar RUN wget ... && dpkg -i ...  pero en cambnio algo mas limpio es usar el comando ADD ya que a diferencia de COPY, ADD es capaz de descargar un archivo de internet y copiarlo directamente en el sistema-contenedor.

 * Mirar diferencia entre ADD y COPY

 * Cuando vamos a copiar diferentes archivos de configuración de servicios, en vez de usar el comando COPY lo mejor es montar directamente desde un volumen compartido o desde el docker host, el directorio que los contiene, en el directorio donde necesitan estar dentro del contenedor. De esta manera incluso podróamos editarlos desde local y tomarían efecto en el contenedor sin reacer la imagen.

 * Es una buena practica usar el CMD al final del archivo aunque no haga falta, debido a que el CMD de la imagen padre 'FROM' ya lo contiene. Es decir repetiremos el CMD de la imagen padre para el que use nuestras imágenes sepa que comando es el que acaba iniciando nuestro contenedor y no tenga que ir dentro del dockerfile de la iamgen padre dentro de dockerhub. Es por tema de documentación y clarificación principalmente.

 * Mirar extensiones de docker.. ¿docker-php-ext-configure?

 * Interesante el uso del mapping con

 	RUN { \
 				echo parametro1=valor1; \
 				echo parametro2: "valor2"; \
 				echo parametro3 valor3; \
 				...
 			} > /arvhico/de/configuracion

 	Aunque cuidado porque si son límites que cambian de unos entornos a otros es mejor usar ENV.


* Mirar los docerfile multistage (varios FROMl)

* HEALTHCHECK en Dockerfile puede hacerte independiente de la forma en la que despliegues.

* En los compose es una buena práctica el crear una red para despliegues de cluster y exponer los puertos en modo host, de esta forma evitamos pasar el tráfico por las redes mesh y overlay y tenemos acceso directo a la NIC.

Además de lo anterior, cuando tenemos una sola instancia de un servicio como base de datos, y queremos tener acceso directo a la NIC sin pasar por la VIP de la network creada para el cluster, podemos usar el modo "endpoint_mode: dnsrr" en el apartado deploy. Con esto conseguiremos mejor eficiencia en el networking.

* Usar limitaciones de recursos para los contenedores cada vez que sea posible.

* Otro parámetro interesante en los cluster para usar en el compose es "placement" > "constraints" para poner renstricciones, por ejemplo que un cierto contenedor, se despliegue en un nodo en concreto, dado su nombre.

master1:
	deploy:
		placement:
			contraints: [ node.hostname == node-1]

Lo anterior igual se puede hacer mejor cuando son muchos nodos, usando etiquetas y o diciendo donde no deben de situarse, o darles preferencias a ciertas etiquetas de donde si queremos que estén por ejemplo teniendo zonas de disponibilidad y haciendo que siempre haya un nodo (el que sea) por zona de disponibilidad. Ademas si en cada zona tenemos dos nodos, uno de data y otro master, podríamos desplegar temporalmente el master en el de data, asi no perdemos servicio mientras se recupera el nodo master y el contenedor volveria a pasar alli.

* Rex Ray que es?? creo que es un driver para almacenamiento compartido en docker.

* En clister, mejor que tner los datos en cada nodo, por ejemplo un master, tiene los datos en su coker-host, otro master en su otro dockerhost, un slave en su dockerhost, etc... igual es mejor tener un alamcenamiento compartido, cada nodo con su espacio en un directorio, uincluso este podŕia estar limitado con limitaciones del contenedor o del sistema con cgroup, y en caso de caer ese nodo y levantarse en otro nodo, volveria a conectar y tendria los mismos datos que antes de caerse.

* Here's some resources for PHP developers.

First, I have my "good defaults" template project here: https://github.com/BretFisher/php-docker-good-defaults

* https://www.bretfisher.com/docker-certified-associate/

* https://success.docker.com/certification

* https://patreon.com/BretFisher

* www.bretfisher.com/newsletter

* https://www.udemy.com/course/docker-mastery/?couponCode=JULY20C1

*  https://www.udemy.com/course/kubernetesmastery/?couponCode=JULY20C4


* Una buena web para buenas práccticas Autopilot Pattern Applications

* Tres carácteristicas avanzadas de docker que la gente no usa: oreilly.com -> 3-docker-compose-features-for-improving-team-development-workflow

	una de ellas es muy improtante que es definir ubn bloque de código y luego usarlo a traves de una variable...

* Shortcut Ctrl+PQ cuando estoy dentro de un contenedor para salirme a la terminal sin parar el contenedor.
	Si ahora ejecuto docker container attach <contenedor>  vuelvo a acceder al bash que tenía lanzado el contenedor e igualmente podré salir con el shortcut. Si por contra ejecuto docker container exec -it <contenedor> /bin/bash estaré abriendo un nuevo proceso bash dentro del contenedor que podremos ver desde la terminal del contendor con ps -ef. Si dentro hacemos exit, matamos ese proceso pero aún tenemos el antiguo proceso bash al que hacer un attach.

* corregir en el libro docker para todos las capasd de las que está formado docker. libcontainer ha sustituido a LXC y las capas desarrolladas son: docker client -> docker engine (API, manejo de plugins, interacción cliente-capas inferiores) -> containerd (encargado del lifecycle de los contenedores; start, stop, pause, rm, uso de imágenes, creación de la capa de red y persistencia...) -> shim (aunque containerd lanza la creación de los contenedores através de runc, cuando runc crea el contenedor, deja de ser el proceso padre de estos y entonces el proceso runc desaparece y shim toma el control por lo que desacopla el contenedor del demonio docker-engine. Shim maneja las STDIN y STDOUT asi como el estado del contenedor. -> runc (encargado de instanciar contenedores sobre o haciendo uso de libcontainer, namespaces, cgroups...). Hablar de OCI layer.

Lo bueno de containerd es que permite crear contenedores en windows al no usarse la tecnologia nativa de linux LXC. También aunque empezó con proposito de una capa de poco peso, se le fueron añadiendo mas funcionalidades como el manejo de persistencia y redes. Ahora containerd se ha vuelto la tecnologia defacto a usar en kubernetes dando la posibilidad de usar solo aquellas funcionalidades necesarias. También containerd es ejecutado por docker-engine atraves de su api la cual fue instanciada desde el cliente de docker. COntainerd llama a runc para crear el contenedor y en cuanto es creado runc muere como proceso y pasa el control a Shim, una capa de contained que finalmente nos ha permitido desacoplar por completo la gestión del contenedor por medio de docker-engine, a diferencia de versiones previas a la 1.11 donde docker-engine administraba todo como aplicación monolitica. Ahora podemos aplicar actualizaciones al demonio de docker sin necesidad de parar toda la infraestructura como container.
 el demonio de docker a pesar de haber abandonado muchas funcionalidades en pro de containerd, sigue manteniendo las relacionadas a la contruccion de imagenes, networking, orquestacion, api y seguridad.

* Dangling images son aquellas que por cualquier motivo no han sido tagueadas o bien han sido des-tagueadas cuando ya existía una anterior con un nombre y tag determinado y hemos compilado una nueva con mismo nombre y tag, en este momento la mas antigua será destagueada quedando como dangling image. Podemos ver estas imágenes con el siguiente comando: docker image ls --filter dangling=true y puede ser borradas con docker image prune. Si añadimos '-a' al comando anterior también será eliminadas todas aquellas imágenes que no se estén usando. Otros filtros que acepta el parámetro filter son "before", "since" o "label". O incluso reference como "filter=reference=*:latest". Otro parámetro es --format, por ejemplo docker image ls --format "{{.Repository}}: {{.Tag}}: {{.Size}}".

* docker image digest es bueno para descargar o identificar a las imágenes por su sha256 mejor que por su nombre. UN claro ejemplo donde este comando nos puede ayudar es cuando por ejemplo tenemos una imagen "mywebnginx:1.1" que hemos descargado para mejorar ciertos aspectos de la aplicación, a tiempo de compilar y taguear para subir posteriormente al repositorio hemos cometido un error y la hemos nombrado (tagueado) con el mismo nombre que la anterior "mywebnginx:1.1", la pregunta sería ahora... como detectar en nuestro entorno de testing o producción que imágen estamos testeando o cual esta desplegada en cada nodo?, es aquí donde digest nos puede ayudar a identificar cada imagen. Desde docker 1.10 se introduce el concepto de digest en las imágenes, donde este es un sha del contenido de la imagen por lo que cualquier modificación por pequeña que sea en el contenido de la imagen, haría cambiar el digest. Tanto las capas de una imagen como la imagen en si, son inmutables ya que cualquier cambio ya sea en una de las capas o en en el archivo de configuración de la imagen (Dockerfile) modificaría el hash. UNa cosa a tener en cuenta es que no es lo mismo el hash de un contenido comprimido a descomprimido, por lo tanto cuando ejecutamos un push o pull el hash de la imagen cambia. Cuando hacemos push, dockerhub verifica los hash y comprime la imagen por lo que el hash una vez comprimido y subido es distinto al hash de la imagen una vez hagamos pull, ya que será descargada y descomprimida en nuestro disco. Por ello cuando dockerhub haga la comprobación del hash de cada capa de la imagen, daría error ya que es distinto el que tenemos en local al que el mantiene en el repositorio, por ello se añade un nuevo hash por capa llamado "distribution hash" el cual es un hash de la versión comprimida y es incluído en cada capa de la imagen ya este descomprimida o comprimida.
Otros comandos importantes a utilizar cuando trabajamos con imágenes son, docker manifest, nos permite ver el manifest list de la imagen con lo que sabremos para que arquitecturas/plataformas está cronstruida la imágen (docker manifest inspect <imagen>). También y aunque al momento de escribir esto (agosto 2020) está en versión experimental ()daemon.json) es docker buildx build --platform linux/arm/v7 -t myimage:arm-v7.
