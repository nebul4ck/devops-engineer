docker para todos 2

* conectar con un segundo daemon:

docker context ls

(solo aparece el local)

Si queremos ejecutar comandos en otro daemon sin conectar por ssh a ese daemon:

$ DOCKER_HOST="tcp://ip:2375"

En este caso tendremos la API abierta por TCP (menos seguro)

Para conectar teniendolo configurado en local (el daemon externo)

usamos docker context

$ docker context create --docker "host=tcp://ip:2375" pwd
$ docker contetext ls

podemos hacer un switch de context para usar el nuevo daemon:

$ docker context use pwd


podemos configurar conexiones por ssl o hacer un skip de certificados auto-creados

Es posible configurar el archivo de configuración que se ha generado, por si quisieramos modificar directamente algunos parámetros de la conexion del daemon:

$ cd ~/.docker/contexts/meta/{id}
$ vi meta.json

* A partir de la versión 18, podemos conectar con un daemon remoto mediante SSH.

$ docker context create ssh --docker "host=ssh://myremotehost"

Para utilizar "hostaname" en vez de una cadena de conexión propia de ssh (ssh -l usuario host --parametros) deberíamos de crear una configuración ssh en nuestro archivo de configuración ssh local.

Aquí un ejemplo en el que se accede por ssh a "miremotehost" evitando el fingerprint del hostname remoto, y utilizando un certificado .pem en vez de password.

$ cat ~/.ssh/config

Host myremotehost
  StrickHostKeyCheking no
  Hostname 3.210.133.101
  User ubuntu
  IdentityFile ~/.ssh/myremotehost.pem


* Otra característica de la versión 19 es docker app. Es una opción para compartir aplicaciones de forma mas facil, a traves de paquetes tar en git.

Docker app se instala como un plugin en docker 19.83 y en esta versión aún hay que configurar ~/.docker/config.json para que docker trabaje en experimental:

cd; vi .docker/config.json
{
	"experimental": "enabled"
}

$ 

Docker client plugins Manager : lukaszlach/clip

* Mirar también docker buildx


* Mirar también docker cluster

Preguntas frecuentes:

1. Sobre la seguridad en las imágenes Alpile

Es muy segura debida a la cantidad de archivos, binarios, programas, que han sido eliminados. Uno de los lemas es menos paching, mas seguro.

No obstante, es recomendable ir a producción con imágenes basadas en aquellos sistemas operativos qu acostumbremos usar (Debian, Ubuntu, RHEL, CentOS) debido a que Alpine cambia aspectos importantes como el propio gestor de paquetes, ubicación de archivos y binarios, etc... por lo que al final, si no estás acostumbrado a Alpine, tendrás que realizar un gran esfuerzo al principio, e incluso acostumbrarte a este OS, si quieres ir a producción con los menos problemas posibles. EN la mayoría de los casos, este esfuerzo te hará ahorar algunos MB en tu disco, algo que no es especialmente significativo hoy en día.

Un inconveniente de usar Alpine y tal y como se define en (https://kubedex.com/follow-up-scanning-comparison) es el problema que tienen los escaneadores de vulnerabilidades. Alpine, al modificar rutas de archivos o incluso los distributions back-port patches los escaneadores no encuentren vulnerabilidades en sus paquetes.

2. Apache:

Es buena práctica crear un contenedor con Apache + site de forma asislada a ejecutar un contenedor con Apache + multisite. Esto principalmente es por escalabilidad de un site concreto, la actualización del web site (no tener que tirar todos e iniciar todos)... si tuvieramos cientos de sites, igual conviene agruparlos de forma coherente por contenedores, para optimizar recursos en el servidor.

3. Bases de datos en VM's continers o bare


4. Compose vs swarm en un solo servidor: la recomendación es usar siempre swarm en producción aunque solo sea un host debido a que haremos uso de las ventajas de swarm por ejemplo para hacer un rolling upgrade, o actualizaciones, etc... no tendremos downtime, ni tener que re-hacer todo el trabajo. Además siempre estaremos preparados para escalar.


5. Docker environment configuration

	The twelve-Factor APP (12factor.net/config)

	-> Factores a tener en cuenta al desplegar infraestructuras microservicios.

6. ENTRYPOINT vs CMD

El ENTRYPOINT por defecto (si no se ejecuta el comando ENTRYPOINT dentro del Dockerfile, el cual referencia a un ShellScript) es "/bin/sh -c" es decir se prepara para ejecutar un comando a partir de sh, que comando? pues el que hayamos marcado para ejecutar en la entrada CMD del Dockerfile.

Existen varias formas de anular, sobreescribir o utilizar estas dos entradas de Dockerfile

1. No usamos entrypoint pero si un CMD dentro del Dockerfile

* CMD: ["/bin/echo","Hello World!"]

Resultado al inicializar el contenedor:
	El último comando en ejecutarse tras instanciar el contenedor será:

		$ /bin/sh -c "echo Hello World!"

2. Sobreescribimos el CMD:

	$ docker container run --rm image /bin/ls
	bin
	boot
	dev
	etc
	home
	...

3. Utilizar las entradas ENTRYPOINT y CMD en Dockerfile

	FROM ubuntu:16.04
	ENTRYPOINT ["/bin/echo"]
	CMD ["Hello World!"]

El resultado será el mismo que el del punto 1.

4. Sobreescribir el CMD. Este caso es diferente al punto 2 debido a que en el punto 2 no usábamos ningún ENTRYPOINT por lo tanto se ejecutaba el comando 'ls' a través de /bin/sh -c. Ahora el ENTRYPOINT es un /bin/echo y por ello el valor con el que vamos a sustituir al CMD del paso 3, será un argumento para echo.

	$ docker container run --rm image "Esto difiere del punt 2."
	Esto difiere del punt 2.

5. Por último, veremos como sustituir en tiempo de ejecución tanto en ENTRYPOINT como el CMD del Dockerfile. Suponiendo que continuamos con la imagen cosntruida a partir del paso 3. Vamos a modificar el ENTRYPOINT por "/bin/cat" y el CMD por "/etc/release" con lo cual, al instanciar el contenedor, nos imprimirá la versión del OS.

	$ docker container run --rm --entrypoint="/bin/cat" test /etc/lsb-release
	DISTRIB_ID=Ubuntu
	DISTRIB_RELEASE=16.04
	DISTRIB_CODENAME=xenial
	DISTRIB_DESCRIPTION="Ubuntu 16.04.6 LTS"

Ahora que ya hemos visto las sintaxis del comando ENTRYPOINT y CMD dentro de y fuera de un Dockerfile, decir que estábamos utilizando una de las dos formas en las que estos comandos pueden ser instanciados, en este caso usábamos la "exec form" (["valor1","valor2",...]). La otra forma es la utilizada por el comando RUN del Dockerfile y que también es posible para los dos comandos anteriores y es la "shell form" (<instrucción> <comando>). Veamos un ejemplo:

  	FROM ubuntu:16.04
  	RUN apt update && \
  	  apt install wget -y
  	ENV msg "Hello World!"
  	ENTRYPOINT echo "$msg"

 En este ejemplo hemos añadido la definición de una variable y un ENTRYPOINT. Todos los comandos definidos en este Dockerfile están en "Shell form".

 Para terminar, entonces podemos decir que lo definido en el comando ENTRYPOINT se ejecuta siempre antes de lo definido en CMD y que en la mayoría de las veces, se usa CMD para pasar parámetros a un comando que se ejecutará desde dentro de un Shell Script. Este Shell script será ejecutado a su vez por ENTRYPOINT. Un ejemplo es cuando ENTRYPOINT define un shellscript de configuración de un servicio, por ejemplo nginx o mysql y en su último comando, define un comando para inicializar el servicio en si, en CMD podremos entonces ver algunos parámetros que se le pasarán a este servicio.

6. Estudiar el tema de como usar variables de entornos en Docker y sobretodo como administrar secrets, fuera parte de los métodos de swarm y kubernetes. El entrypoint de mysql oficial tiene algo curioso que no term,ino de descifrar.

7. Dividir muchos vhost de apache en muchos contenedores tiene la particularidad de que es muy fácil manejar de forma independiente las applicaciones, rolling update, escalado, etc... pero la deventaja de que estamos gastando muchos mas recursos al tener tantos apache en la misma máquina. Igual pasa con contenedores de servidores de aplicaciones como tomcat, jboss, oas, etc... Lo mejor es valorar todo, y separar aquello que sea mas dinámico para dejar mas "estanco" lo menos cambiante o aquello que es mas fácil de migrar en un futuro aunque sea cambiante (por ejemplo, la versión del servidor de aplicaciones puede incrementar a consecuencia de nuevos parches y soluciones pero la applicación es poco pesada y facil de administrar y migrar, esto seguramente iría mejor en servidores dedicados.)



* mirar let's encrypt, es una página buena para saber que debemos y que no hacer con la generacion de certificados en local.

* mirar stack-proxy-global para temas decertificados en proxy, etc...


* Probar lo del entrypoint: escribir un shell con funciones etc... que haga cosas al iniciar el servicio y por ultimo coja el CMD como parámetro de la inicialización del servicio. Podemos probar esto con cosas faciles como sustituir valor de variable dada por el CMD como argumento etc...

 * otra práctica es iniciar un stack de aplicaciones en orden. Para esto Bret menciona que están disponible los comandos de compose como respawn, depend_on, etc... en 12 factor también podemos encontrar algo. Montar un stack y conseguir que se orquestre bein.


 * EN los dockerfile hay que tener especial cuidado con los apt get update, ya que poner un solo update al inicio pensando de que actualizara la cache de los paquetes no será cerieto, ya que lo actualizara (los repo) la priemra vez que constuyamos la imagen pero si volvemos a modificar el docker file, incluso incluyendo posteriores apt install de paquetes, ese paso no se olverá a ejecutar porque ya está en la cache de la imagen y esa linea del dockerfile no ha cambiado. El update debe incluirse antes de cualquier RUN apt install que haya en el dockerfile. Recordar puntualizar las versiones de los paquetes al instalar para fijar las verdiones a usar.

 cuando descargamos archivos de internet, solemos usar RUN wget ... && dpkg -i ...  pero en cambnio algo mas limpio es usar el comando ADD ya que a diferencia de COPY, ADD es capaz de descargar un archivo de internet y copiarlo directamente en el sistema-contenedor.

 * Mirar diferencia entre ADD y COPY

 * Cuando vamos a copiar diferentes archivos de configuración de servicios, en vez de usar el comando COPY lo mejor es montar directamente desde un volumen compartido o desde el docker host, el directorio que los contiene, en el directorio donde necesitan estar dentro del contenedor. De esta manera incluso podróamos editarlos desde local y tomarían efecto en el contenedor sin reacer la imagen.

 * Es una buena practica usar el CMD al final del archivo aunque no haga falta, debido a que el CMD de la imagen padre 'FROM' ya lo contiene. Es decir repetiremos el CMD de la imagen padre para el que use nuestras imágenes sepa que comando es el que acaba iniciando nuestro contenedor y no tenga que ir dentro del dockerfile de la iamgen padre dentro de dockerhub. Es por tema de documentación y clarificación principalmente.

 * Mirar extensiones de docker.. ¿docker-php-ext-configure?

 * Interesante el uso del mapping con

 	RUN { \
 				echo parametro1=valor1; \
 				echo parametro2: "valor2"; \
 				echo parametro3 valor3; \
 				...
 			} > /arvhico/de/configuracion

 	Aunque cuidado porque si son límites que cambian de unos entornos a otros es mejor usar ENV.


* Mirar los docerfile multistage (varios FROMl)

* HEALTHCHECK en Dockerfile puede hacerte independiente de la forma en la que despliegues.

* En los compose es una buena práctica el crear una red para despliegues de cluster y exponer los puertos en modo host, de esta forma evitamos pasar el tráfico por las redes mesh y overlay y tenemos acceso directo a la NIC.

Además de lo anterior, cuando tenemos una sola instancia de un servicio como base de datos, y queremos tener acceso directo a la NIC sin pasar por la VIP de la network creada para el cluster, podemos usar el modo "endpoint_mode: dnsrr" en el apartado deploy. Con esto conseguiremos mejor eficiencia en el networking.

* Usar limitaciones de recursos para los contenedores cada vez que sea posible.

* Otro parámetro interesante en los cluster para usar en el compose es "placement" > "constraints" para poner renstricciones, por ejemplo que un cierto contenedor, se despliegue en un nodo en concreto, dado su nombre.

master1:
	deploy:
		placement:
			contraints: [ node.hostname == node-1]

Lo anterior igual se puede hacer mejor cuando son muchos nodos, usando etiquetas y o diciendo donde no deben de situarse, o darles preferencias a ciertas etiquetas de donde si queremos que estén por ejemplo teniendo zonas de disponibilidad y haciendo que siempre haya un nodo (el que sea) por zona de disponibilidad. Ademas si en cada zona tenemos dos nodos, uno de data y otro master, podríamos desplegar temporalmente el master en el de data, asi no perdemos servicio mientras se recupera el nodo master y el contenedor volveria a pasar alli.

* Rex Ray que es?? creo que es un driver para almacenamiento compartido en docker.

* En clister, mejor que tner los datos en cada nodo, por ejemplo un master, tiene los datos en su coker-host, otro master en su otro dockerhost, un slave en su dockerhost, etc... igual es mejor tener un alamcenamiento compartido, cada nodo con su espacio en un directorio, uincluso este podŕia estar limitado con limitaciones del contenedor o del sistema con cgroup, y en caso de caer ese nodo y levantarse en otro nodo, volveria a conectar y tendria los mismos datos que antes de caerse.

* Here's some resources for PHP developers.

First, I have my "good defaults" template project here: https://github.com/BretFisher/php-docker-good-defaults

* https://www.bretfisher.com/docker-certified-associate/

* https://success.docker.com/certification

* https://patreon.com/BretFisher

* www.bretfisher.com/newsletter

* https://www.udemy.com/course/docker-mastery/?couponCode=JULY20C1

*  https://www.udemy.com/course/kubernetesmastery/?couponCode=JULY20C4


* Una buena web para buenas práccticas Autopilot Pattern Applications

* Tres carácteristicas avanzadas de docker que la gente no usa: oreilly.com -> 3-docker-compose-features-for-improving-team-development-workflow

	una de ellas es muy improtante que es definir ubn bloque de código y luego usarlo a traves de una variable...


